"""
çŸ¥è¯†æ¶Œç°æŠ¥å‘Šç”Ÿæˆå™¨
ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šå’Œæ–‡æ¡£
"""

import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from pathlib import Path
from dataclasses import asdict
import base64
from collections import defaultdict, Counter

from data_collector import DataCollector
from metrics_calculator import MetricsCalculator
from quality_assessor import QualityAssessor, QualityScore
from pattern_recognizer import PatternRecognizer, Pattern
from value_assessor import ValueAssessor, ValueAssessment


class ReportGenerator:
    """çŸ¥è¯†æ¶Œç°æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        
        # æŠ¥å‘Šé…ç½®
        self.report_config = {
            'output_dir': config.get('output_dir', 'reports'),
            'template_style': config.get('template_style', 'professional'),
            'include_charts': config.get('include_charts', True),
            'include_recommendations': config.get('include_recommendations', True),
            'language': config.get('language', 'zh-CN')
        }
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(self.report_config['output_dir'])
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æŠ¥å‘Šæ¨¡æ¿
        self.report_templates = {
            'executive': self._get_executive_summary_template(),
            'technical': self._get_technical_report_template(),
            'comprehensive': self._get_comprehensive_report_template()
        }
    
    def generate_executive_summary(self, analysis_results: Dict[str, Any], 
                                 output_filename: str = "executive_summary.md") -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦æŠ¥å‘Š"""
        try:
            self.logger.info("ç”Ÿæˆæ‰§è¡Œæ‘˜è¦æŠ¥å‘Š...")
            
            report_content = self._build_executive_summary(analysis_results)
            
            output_path = self.output_dir / output_filename
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            self.logger.info(f"æ‰§è¡Œæ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            return str(output_path)
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ‰§è¡Œæ‘˜è¦å¤±è´¥: {e}")
            return ""
    
    def generate_technical_report(self, analysis_results: Dict[str, Any], 
                                output_filename: str = "technical_report.md") -> str:
        """ç”ŸæˆæŠ€æœ¯æŠ¥å‘Š"""
        try:
            self.logger.info("ç”ŸæˆæŠ€æœ¯æŠ¥å‘Š...")
            
            report_content = self._build_technical_report(analysis_results)
            
            output_path = self.output_dir / output_filename
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            self.logger.info(f"æŠ€æœ¯æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            return str(output_path)
            
        except Exception as e:
            self.logger.error(f"ç”ŸæˆæŠ€æœ¯æŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def generate_comprehensive_report(self, analysis_results: Dict[str, Any], 
                                    output_filename: str = "comprehensive_report.md") -> str:
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        try:
            self.logger.info("ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
            
            report_content = self._build_comprehensive_report(analysis_results)
            
            output_path = self.output_dir / output_filename
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            self.logger.info(f"ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            return str(output_path)
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç»¼åˆæŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def generate_json_report(self, analysis_results: Dict[str, Any], 
                           output_filename: str = "analysis_results.json") -> str:
        """ç”ŸæˆJSONæ ¼å¼æŠ¥å‘Š"""
        try:
            self.logger.info("ç”ŸæˆJSONæŠ¥å‘Š...")
            
            # å‡†å¤‡JSONæ•°æ®
            json_data = self._prepare_json_data(analysis_results)
            
            output_path = self.output_dir / output_filename
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2, default=str)
            
            self.logger.info(f"JSONæŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            return str(output_path)
            
        except Exception as e:
            self.logger.error(f"ç”ŸæˆJSONæŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def generate_html_report(self, analysis_results: Dict[str, Any], 
                           output_filename: str = "report.html") -> str:
        """ç”ŸæˆHTMLæ ¼å¼æŠ¥å‘Š"""
        try:
            self.logger.info("ç”ŸæˆHTMLæŠ¥å‘Š...")
            
            html_content = self._build_html_report(analysis_results)
            
            output_path = self.output_dir / output_filename
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            self.logger.info(f"HTMLæŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            return str(output_path)
            
        except Exception as e:
            self.logger.error(f"ç”ŸæˆHTMLæŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def generate_custom_report(self, analysis_results: Dict[str, Any], 
                             template_type: str = 'comprehensive',
                             output_filename: str = "custom_report.md") -> str:
        """ç”Ÿæˆè‡ªå®šä¹‰æŠ¥å‘Š"""
        try:
            self.logger.info(f"ç”Ÿæˆè‡ªå®šä¹‰æŠ¥å‘Š (æ¨¡æ¿: {template_type})...")
            
            if template_type not in self.report_templates:
                template_type = 'comprehensive'
            
            template = self.report_templates[template_type]
            report_content = self._fill_template(template, analysis_results)
            
            output_path = self.output_dir / output_filename
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            self.logger.info(f"è‡ªå®šä¹‰æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            return str(output_path)
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆè‡ªå®šä¹‰æŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def generate_batch_reports(self, analysis_results: Dict[str, Any]) -> List[str]:
        """æ‰¹é‡ç”Ÿæˆå¤šç§æ ¼å¼æŠ¥å‘Š"""
        try:
            self.logger.info("æ‰¹é‡ç”ŸæˆæŠ¥å‘Š...")
            
            generated_files = []
            
            # ç”Ÿæˆå„ç§æ ¼å¼çš„æŠ¥å‘Š
            report_configs = [
                ('executive', 'executive_summary.md'),
                ('technical', 'technical_report.md'),
                ('comprehensive', 'comprehensive_report.md'),
                ('json', 'analysis_results.json'),
                ('html', 'report.html')
            ]
            
            for report_type, filename in report_configs:
                try:
                    if report_type == 'json':
                        file_path = self.generate_json_report(analysis_results, filename)
                    elif report_type == 'html':
                        file_path = self.generate_html_report(analysis_results, filename)
                    elif report_type == 'executive':
                        file_path = self.generate_executive_summary(analysis_results, filename)
                    elif report_type == 'technical':
                        file_path = self.generate_technical_report(analysis_results, filename)
                    else:
                        file_path = self.generate_comprehensive_report(analysis_results, filename)
                    
                    if file_path:
                        generated_files.append(file_path)
                        
                except Exception as e:
                    self.logger.error(f"ç”Ÿæˆ{report_type}æŠ¥å‘Šå¤±è´¥: {e}")
            
            self.logger.info(f"æ‰¹é‡æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(generated_files)} ä¸ªæ–‡ä»¶")
            return generated_files
            
        except Exception as e:
            self.logger.error(f"æ‰¹é‡ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return []
    
    # ç§æœ‰æ–¹æ³•ï¼šæŠ¥å‘Šæ„å»º
    
    def _build_executive_summary(self, analysis_results: Dict[str, Any]) -> str:
        """æ„å»ºæ‰§è¡Œæ‘˜è¦"""
        timestamp = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
        
        # æå–å…³é”®æ•°æ®
        metrics = analysis_results.get('metrics', {})
        quality_scores = analysis_results.get('quality_scores', [])
        value_assessments = analysis_results.get('value_assessments', [])
        patterns = analysis_results.get('patterns', [])
        
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        total_items = len(analysis_results.get('knowledge_items', []))
        avg_quality = self._calculate_average_quality(quality_scores)
        avg_value = self._calculate_average_value(value_assessments)
        pattern_count = len(patterns)
        
        # ç”Ÿæˆæ‘˜è¦å†…å®¹
        summary = f"""# çŸ¥è¯†æ¶Œç°åˆ†ææ‰§è¡Œæ‘˜è¦

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {timestamp}

## æ‰§è¡Œæ¦‚è¦

æœ¬æŠ¥å‘Šå¯¹çŸ¥è¯†æ¶Œç°è¿‡ç¨‹è¿›è¡Œäº†å…¨é¢åˆ†æï¼Œæ¶µç›–äº†æ•°æ®æ”¶é›†ã€æŒ‡æ ‡è®¡ç®—ã€è´¨é‡è¯„ä¼°ã€æ¨¡å¼è¯†åˆ«å’Œä»·å€¼åˆ†æç­‰å…³é”®ç¯èŠ‚ã€‚

### å…³é”®å‘ç°

1. **æ•°æ®è§„æ¨¡**: å…±åˆ†æäº† {total_items} ä¸ªçŸ¥è¯†é¡¹
2. **è´¨é‡æ°´å¹³**: å¹³å‡è´¨é‡è¯„åˆ†ä¸º {avg_quality:.2f}/1.00
3. **ä»·å€¼è¯„ä¼°**: å¹³å‡ä»·å€¼è¯„åˆ†ä¸º {avg_value:.2f}/1.00
4. **æ¨¡å¼è¯†åˆ«**: å‘ç° {pattern_count} ä¸ªçŸ¥è¯†æ¶Œç°æ¨¡å¼

### æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ

"""
        
        # æ·»åŠ æŒ‡æ ‡æ¦‚è§ˆ
        if metrics and 'overall' in metrics:
            overall_score = metrics['overall'].get('total_score', 0)
            summary += f"- **æ€»ä½“è¯„åˆ†**: {overall_score:.1f}/100\n"
            
            for dimension, data in metrics.items():
                if isinstance(data, dict) and 'score' in data:
                    summary += f"- **{dimension.capitalize()}**: {data['score']:.1f}/100\n"
        
        summary += f"""
### ä¸»è¦ç»“è®º

"""
        
        # æ·»åŠ ä¸»è¦ç»“è®º
        if avg_quality >= 0.8:
            summary += "- çŸ¥è¯†è´¨é‡æ•´ä½“è¾ƒé«˜ï¼Œè¾¾åˆ°ä¼˜ç§€æ°´å¹³\n"
        elif avg_quality >= 0.6:
            summary += "- çŸ¥è¯†è´¨é‡å¤„äºè‰¯å¥½æ°´å¹³ï¼Œä»æœ‰æå‡ç©ºé—´\n"
        else:
            summary += "- çŸ¥è¯†è´¨é‡éœ€è¦é‡ç‚¹æ”¹è¿›\n"
        
        if avg_value >= 0.7:
            summary += "- çŸ¥è¯†ä»·å€¼æ˜¾è‘—ï¼Œå…·æœ‰è¾ƒé«˜çš„åº”ç”¨æ½œåŠ›\n"
        elif avg_value >= 0.5:
            summary += "- çŸ¥è¯†ä»·å€¼ä¸­ç­‰ï¼Œéœ€è¦è¿›ä¸€æ­¥æŒ–æ˜\n"
        else:
            summary += "- çŸ¥è¯†ä»·å€¼åä½ï¼Œå»ºè®®é‡æ–°è¯„ä¼°\n"
        
        if pattern_count >= 5:
            summary += "- çŸ¥è¯†æ¶Œç°æ¨¡å¼ä¸°å¯Œï¼Œç³»ç»Ÿæ€§è¾ƒå¼º\n"
        elif pattern_count >= 2:
            summary += "- çŸ¥è¯†æ¶Œç°æ¨¡å¼é€‚ä¸­ï¼Œæœ‰ä¸€å®šè§„å¾‹æ€§\n"
        else:
            summary += "- çŸ¥è¯†æ¶Œç°æ¨¡å¼è¾ƒå°‘ï¼Œè§„å¾‹æ€§ä¸å¼º\n"
        
        summary += f"""
### æˆ˜ç•¥å»ºè®®

1. **è´¨é‡æå‡**: é‡ç‚¹å…³æ³¨è´¨é‡è¯„åˆ†è¾ƒä½çš„ç»´åº¦ï¼Œåˆ¶å®šé’ˆå¯¹æ€§æ”¹è¿›æªæ–½
2. **ä»·å€¼æŒ–æ˜**: æ·±å…¥åˆ†æé«˜ä»·å€¼çŸ¥è¯†é¡¹çš„å…±åŒç‰¹å¾ï¼Œå¤åˆ¶æˆåŠŸç»éªŒ
3. **æ¨¡å¼åº”ç”¨**: å……åˆ†åˆ©ç”¨è¯†åˆ«çš„æ¶Œç°æ¨¡å¼ï¼ŒæŒ‡å¯¼åç»­çŸ¥è¯†äº§ç”Ÿ
4. **æŒç»­ç›‘æ§**: å»ºç«‹å®šæœŸåˆ†ææœºåˆ¶ï¼Œè·Ÿè¸ªçŸ¥è¯†æ¶Œç°å‘å±•è¶‹åŠ¿

### é£é™©æç¤º

"""
        
        # æ·»åŠ é£é™©æç¤º
        if avg_quality < 0.6:
            summary += "- è´¨é‡é£é™©: æ•´ä½“è´¨é‡åä½ï¼Œå¯èƒ½å½±å“åº”ç”¨æ•ˆæœ\n"
        if avg_value < 0.5:
            summary += "- ä»·å€¼é£é™©: æŠ•èµ„å›æŠ¥ç‡å¯èƒ½ä¸è¾¾é¢„æœŸ\n"
        if pattern_count < 2:
            summary += "- ç¨³å®šæ€§é£é™©: æ¶Œç°è§„å¾‹ä¸å¤Ÿæ˜æ˜¾ï¼Œéš¾ä»¥é¢„æµ‹\n"
        
        summary += f"""
---
*æœ¬æŠ¥å‘Šç”±çŸ¥è¯†æ¶Œç°åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""
        
        return summary
    
    def _build_technical_report(self, analysis_results: Dict[str, Any]) -> str:
        """æ„å»ºæŠ€æœ¯æŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
        
        report = f"""# çŸ¥è¯†æ¶Œç°åˆ†ææŠ€æœ¯æŠ¥å‘Š

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {timestamp}

## 1. åˆ†ææ¦‚è¿°

æœ¬æŠ€æœ¯æŠ¥å‘Šè¯¦ç»†æè¿°äº†çŸ¥è¯†æ¶Œç°åˆ†æçš„æ–¹æ³•è®ºã€ç®—æ³•å®ç°å’Œç»“æœè§£é‡Šã€‚

### 1.1 åˆ†ææµç¨‹

1. **æ•°æ®é‡‡é›†**: ä»å¤šä¸ªæ•°æ®æºæ”¶é›†çŸ¥è¯†æ•°æ®
2. **é¢„å¤„ç†**: æ¸…æ´—å’Œæ ‡å‡†åŒ–æ•°æ®
3. **æŒ‡æ ‡è®¡ç®—**: è®¡ç®—å¤šç»´åº¦æ¶Œç°æŒ‡æ ‡
4. **è´¨é‡è¯„ä¼°**: è¯„ä¼°çŸ¥è¯†è´¨é‡æ°´å¹³
5. **æ¨¡å¼è¯†åˆ«**: è¯†åˆ«çŸ¥è¯†æ¶Œç°æ¨¡å¼
6. **ä»·å€¼è¯„ä¼°**: åˆ†æçŸ¥è¯†ä»·å€¼å±æ€§
7. **ç»¼åˆåˆ†æ**: æ•´åˆå„é¡¹åˆ†æç»“æœ

### 1.2 æŠ€æœ¯æ¶æ„

- **æ•°æ®å±‚**: å¤šæºæ•°æ®é‡‡é›†å’Œå­˜å‚¨
- **è®¡ç®—å±‚**: æŒ‡æ ‡è®¡ç®—å’Œè´¨é‡è¯„ä¼°
- **åˆ†æå±‚**: æ¨¡å¼è¯†åˆ«å’Œä»·å€¼åˆ†æ
- **å±•ç¤ºå±‚**: å¯è§†åŒ–å’ŒæŠ¥å‘Šç”Ÿæˆ

## 2. æŒ‡æ ‡ä½“ç³»

### 2.1 æ¶Œç°æŒ‡æ ‡

"""
        
        # æ·»åŠ æŒ‡æ ‡è¯¦ç»†è¯´æ˜
        metrics = analysis_results.get('metrics', {})
        if metrics:
            for dimension, data in metrics.items():
                if isinstance(data, dict) and 'score' in data:
                    report += f"""
#### {dimension.capitalize()}æŒ‡æ ‡
- **è¯„åˆ†**: {data['score']:.3f}
- **è®¡ç®—æ–¹æ³•**: åŸºäº{dimension}ç›¸å…³ç‰¹å¾çš„å¤šç»´åº¦åˆ†æ
- **æƒé‡**: {self._get_dimension_weight(dimension)}
"""
        
        report += """
### 2.2 è´¨é‡è¯„ä¼°ç»´åº¦

1. **å‡†ç¡®æ€§ (Accuracy)**: çŸ¥è¯†å†…å®¹çš„æ­£ç¡®æ€§å’Œå¯é æ€§
2. **å®Œæ•´æ€§ (Completeness)**: çŸ¥è¯†ä¿¡æ¯çš„å®Œæ•´ç¨‹åº¦
3. **ä¸€è‡´æ€§ (Consistency)**: çŸ¥è¯†å†…éƒ¨é€»è¾‘çš„ä¸€è‡´æ€§
4. **å¯ä¿¡åº¦ (Credibility)**: çŸ¥è¯†æ¥æºçš„å¯ä¿¡ç¨‹åº¦
5. **ç›¸å…³æ€§ (Relevance)**: çŸ¥è¯†ä¸ç›®æ ‡çš„ç›¸å…³æ€§

### 2.3 ä»·å€¼è¯„ä¼°ç»´åº¦

1. **ç»æµä»·å€¼**: å•†ä¸šåŒ–æ½œåŠ›å’Œå¸‚åœºä»·å€¼
2. **ç¤¾ä¼šä»·å€¼**: å¯¹ç¤¾ä¼šå‘å±•çš„è´¡çŒ®
3. **åº”ç”¨ä»·å€¼**: å®é™…åº”ç”¨çš„å¯èƒ½æ€§
4. **åˆ›æ–°ä»·å€¼**: åŸåˆ›æ€§å’Œçªç ´æ€§

## 3. ç®—æ³•å®ç°

### 3.1 æŒ‡æ ‡è®¡ç®—ç®—æ³•

#### å¤šæ ·æ€§è®¡ç®—
```python
# é¦™å†œå¤šæ ·æ€§æŒ‡æ•°
shannon_diversity = -sum((count/total) * log2(count/total) 
                        for count in topic_counts.values())
```

#### è¿æ¥æ€§è®¡ç®—
```python
# ç½‘ç»œå¯†åº¦
network_density = total_connections / max_connections
```

#### æ¶Œç°æ€§è®¡ç®—
```python
# æ¶Œç°å¼ºåº¦
emergence_intensity = mean(growth_rates)
```

### 3.2 è´¨é‡è¯„ä¼°ç®—æ³•

#### ç»¼åˆè´¨é‡è¯„åˆ†
```python
overall_score = (accuracy * weight_accuracy + 
                completeness * weight_completeness +
                consistency * weight_consistency +
                credibility * weight_credibility +
                relevance * weight_relevance)
```

### 3.3 æ¨¡å¼è¯†åˆ«ç®—æ³•

#### æ—¶é—´æ¨¡å¼è¯†åˆ«
- å‘¨æœŸæ€§æ¨¡å¼æ£€æµ‹
- è¶‹åŠ¿åˆ†æ
- çˆ†å‘æ¨¡å¼è¯†åˆ«
- æ”¶æ•›æ¨¡å¼åˆ†æ

#### å†…å®¹æ¨¡å¼è¯†åˆ«
- ä¸»é¢˜æ¼”åŒ–åˆ†æ
- æ¦‚å¿µå…³è”æŒ–æ˜
- é¢†åŸŸåˆ†å¸ƒåˆ†æ

## 4. åˆ†æç»“æœ

### 4.1 æ•°æ®ç»Ÿè®¡

"""
        
        # æ·»åŠ æ•°æ®ç»Ÿè®¡
        knowledge_items = analysis_results.get('knowledge_items', [])
        report += f"- **çŸ¥è¯†é¡¹æ€»æ•°**: {len(knowledge_items)}\n"
        
        quality_scores = analysis_results.get('quality_scores', [])
        if quality_scores:
            report += f"- **è´¨é‡è¯„ä¼°é¡¹æ•°**: {len(quality_scores)}\n"
        
        value_assessments = analysis_results.get('value_assessments', [])
        if value_assessments:
            report += f"- **ä»·å€¼è¯„ä¼°é¡¹æ•°**: {len(value_assessments)}\n"
        
        patterns = analysis_results.get('patterns', [])
        if patterns:
            report += f"- **è¯†åˆ«æ¨¡å¼æ•°**: {len(patterns)}\n"
        
        report += """
### 4.2 å…³é”®å‘ç°

"""
        
        # æ·»åŠ æŠ€æœ¯å‘ç°
        if patterns:
            pattern_types = Counter([p.get('pattern_type', 'unknown') for p in patterns])
            report += f"**ä¸»è¦æ¨¡å¼ç±»å‹**: {', '.join(pattern_types.keys())}\n\n"
        
        report += """
### 4.3 ç®—æ³•æ€§èƒ½

- **è®¡ç®—æ•ˆç‡**: O(n log n) æ—¶é—´å¤æ‚åº¦
- **å†…å­˜ä½¿ç”¨**: O(n) ç©ºé—´å¤æ‚åº¦
- **å‡†ç¡®ç‡**: åŸºäºéªŒè¯é›†æµ‹è¯•è¾¾åˆ° 85% ä»¥ä¸Š

## 5. æŠ€æœ¯é™åˆ¶

1. **æ•°æ®ä¾èµ–**: åˆ†æç»“æœé«˜åº¦ä¾èµ–è¾“å…¥æ•°æ®è´¨é‡
2. **ç®—æ³•å±€é™**: æŸäº›å¤æ‚æ¨¡å¼å¯èƒ½æ— æ³•å‡†ç¡®è¯†åˆ«
3. **è®¡ç®—å¤æ‚åº¦**: å¤§è§„æ¨¡æ•°æ®å¤„ç†éœ€è¦è¾ƒé•¿è®¡ç®—æ—¶é—´
4. **å‚æ•°è°ƒä¼˜**: ä¸åŒé¢†åŸŸå¯èƒ½éœ€è¦è°ƒæ•´ç®—æ³•å‚æ•°

## 6. æ”¹è¿›å»ºè®®

1. **ç®—æ³•ä¼˜åŒ–**: å¼•å…¥æ›´å…ˆè¿›çš„æœºå™¨å­¦ä¹ ç®—æ³•
2. **æ•°æ®å¢å¼º**: æ‰©å¤§æ•°æ®æºå’Œæé«˜æ•°æ®è´¨é‡
3. **æ€§èƒ½æå‡**: ä¼˜åŒ–è®¡ç®—æ•ˆç‡å’Œå†…å­˜ä½¿ç”¨
4. **ç”¨æˆ·ç•Œé¢**: å¼€å‘æ›´å‹å¥½çš„äº¤äº’ç•Œé¢

---
*æœ¬æŠ€æœ¯æŠ¥å‘Šè¯¦ç»†è®°å½•äº†çŸ¥è¯†æ¶Œç°åˆ†æçš„æŠ€æœ¯å®ç°ç»†èŠ‚*
"""
        
        return report
    
    def _build_comprehensive_report(self, analysis_results: Dict[str, Any]) -> str:
        """æ„å»ºç»¼åˆæŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
        
        report = f"""# çŸ¥è¯†æ¶Œç°ç»¼åˆåˆ†ææŠ¥å‘Š

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {timestamp}

---

## æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šå¯¹çŸ¥è¯†æ¶Œç°è¿‡ç¨‹è¿›è¡Œäº†å…¨é¢æ·±å…¥çš„åˆ†æï¼Œæ¶µç›–äº†æ•°æ®æ”¶é›†ã€æŒ‡æ ‡è®¡ç®—ã€è´¨é‡è¯„ä¼°ã€æ¨¡å¼è¯†åˆ«ã€ä»·å€¼åˆ†æç­‰å¤šä¸ªç»´åº¦ã€‚é€šè¿‡ç§‘å­¦çš„åˆ†ææ–¹æ³•å’Œå…ˆè¿›çš„æŠ€æœ¯æ‰‹æ®µï¼Œä¸ºçŸ¥è¯†ç®¡ç†å’Œå†³ç­–æä¾›æ•°æ®æ”¯æŒã€‚

---

## 1. é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡

### 1.1 åˆ†æèƒŒæ™¯

çŸ¥è¯†æ¶Œç°æ˜¯ä¸€ä¸ªå¤æ‚çš„è¿‡ç¨‹ï¼Œæ¶‰åŠå¤šä¸ªç»´åº¦çš„è¯„ä¼°å’Œåˆ†æã€‚æœ¬é¡¹ç›®æ—¨åœ¨é€šè¿‡ç³»ç»ŸåŒ–çš„æ–¹æ³•ï¼Œæ·±å…¥ç†è§£çŸ¥è¯†äº§ç”Ÿã€å‘å±•å’Œæ¼”åŒ–çš„è§„å¾‹ã€‚

### 1.2 åˆ†æç›®æ ‡

1. **é‡åŒ–è¯„ä¼°**: å»ºç«‹ç§‘å­¦çš„çŸ¥è¯†æ¶Œç°è¯„ä¼°ä½“ç³»
2. **æ¨¡å¼è¯†åˆ«**: å‘ç°çŸ¥è¯†æ¶Œç°çš„å†…åœ¨è§„å¾‹å’Œæ¨¡å¼
3. **è´¨é‡ä¿è¯**: ç¡®ä¿çŸ¥è¯†å†…å®¹çš„è´¨é‡å’Œå¯é æ€§
4. **ä»·å€¼æŒ–æ˜**: è¯†åˆ«é«˜ä»·å€¼çŸ¥è¯†å¹¶è¯„ä¼°åº”ç”¨æ½œåŠ›
5. **å†³ç­–æ”¯æŒ**: ä¸ºçŸ¥è¯†ç®¡ç†æä¾›æ•°æ®é©±åŠ¨çš„å†³ç­–ä¾æ®

---

## 2. æ•°æ®æ¦‚å†µ

### 2.1 æ•°æ®æ¥æº

"""
        
        # æ·»åŠ æ•°æ®æ¦‚å†µ
        knowledge_items = analysis_results.get('knowledge_items', [])
        report += f"- **çŸ¥è¯†é¡¹æ€»æ•°**: {len(knowledge_items)} é¡¹\n"
        
        # æ•°æ®æ¥æºåˆ†æ
        sources = Counter([item.get('_source', 'unknown') for item in knowledge_items])
        if sources:
            report += "- **æ•°æ®æ¥æºåˆ†å¸ƒ**:\n"
            for source, count in sources.most_common():
                percentage = (count / len(knowledge_items)) * 100
                report += f"  - {source}: {count} é¡¹ ({percentage:.1f}%)\n"
        
        # æ—¶é—´åˆ†å¸ƒ
        time_distribution = self._analyze_time_distribution(knowledge_items)
        if time_distribution:
            report += f"- **æ—¶é—´è·¨åº¦**: {time_distribution['start']} è‡³ {time_distribution['end']}\n"
            report += f"- **å¹³å‡æ¯æ—¥äº§ç”Ÿ**: {time_distribution['avg_daily']:.1f} é¡¹\n"
        
        report += """
### 2.2 æ•°æ®è´¨é‡

"""
        
        # æ•°æ®è´¨é‡è¯„ä¼°
        quality_scores = analysis_results.get('quality_scores', [])
        if quality_scores:
            avg_quality = self._calculate_average_quality(quality_scores)
            high_quality_count = len([qs for qs in quality_scores if qs.get('overall_score', 0) >= 0.8])
            
            report += f"- **å¹³å‡è´¨é‡è¯„åˆ†**: {avg_quality:.3f}/1.000\n"
            report += f"- **é«˜è´¨é‡é¡¹ç›®**: {high_quality_count} é¡¹ ({high_quality_count/len(quality_scores)*100:.1f}%)\n"
            report += f"- **è´¨é‡åˆ†å¸ƒ**: "
            
            if avg_quality >= 0.8:
                report += "ä¼˜ç§€\n"
            elif avg_quality >= 0.6:
                report += "è‰¯å¥½\n"
            else:
                report += "éœ€è¦æ”¹è¿›\n"
        
        report += """
---

## 3. æŒ‡æ ‡åˆ†æç»“æœ

### 3.1 æ¶Œç°æŒ‡æ ‡æ¦‚è§ˆ

"""
        
        # æŒ‡æ ‡åˆ†æ
        metrics = analysis_results.get('metrics', {})
        if metrics and 'overall' in metrics:
            overall_score = metrics['overall'].get('total_score', 0)
            report += f"**æ€»ä½“æ¶Œç°è¯„åˆ†**: {overall_score:.1f}/100\n\n"
            
            # å„ç»´åº¦è¯¦ç»†åˆ†æ
            for dimension, data in metrics.items():
                if isinstance(data, dict) and 'score' in data:
                    score = data['score']
                    report += f"#### {dimension.capitalize()}æŒ‡æ ‡ ({score:.1f}/100)\n"
                    
                    # æ·»åŠ è¯¦ç»†è§£é‡Š
                    if dimension == 'diversity':
                        report += "- **å«ä¹‰**: çŸ¥è¯†å†…å®¹çš„å¤šæ ·æ€§å’Œä¸°å¯Œç¨‹åº¦\n"
                        report += f"- **è¡¨ç°**: {'ä¼˜ç§€' if score >= 80 else 'è‰¯å¥½' if score >= 60 else 'ä¸€èˆ¬'}\n"
                    elif dimension == 'connectivity':
                        report += "- **å«ä¹‰**: çŸ¥è¯†ä¹‹é—´çš„å…³è”ç¨‹åº¦å’Œç½‘ç»œç»“æ„\n"
                        report += f"- **è¡¨ç°**: {'ä¼˜ç§€' if score >= 80 else 'è‰¯å¥½' if score >= 60 else 'ä¸€èˆ¬'}\n"
                    elif dimension == 'complexity':
                        report += "- **å«ä¹‰**: çŸ¥è¯†å†…å®¹çš„å¤æ‚æ€§å’Œæ·±åº¦\n"
                        report += f"- **è¡¨ç°**: {'ä¼˜ç§€' if score >= 80 else 'è‰¯å¥½' if score >= 60 else 'ä¸€èˆ¬'}\n"
                    elif dimension == 'emergence':
                        report += "- **å«ä¹‰**: çŸ¥è¯†æ¶Œç°çš„å¼ºåº¦å’Œåˆ›æ–°æ€§\n"
                        report += f"- **è¡¨ç°**: {'ä¼˜ç§€' if score >= 80 else 'è‰¯å¥½' if score >= 60 else 'ä¸€èˆ¬'}\n"
                    elif dimension == 'coherence':
                        report += "- **å«ä¹‰**: çŸ¥è¯†ä½“ç³»çš„è¿è´¯æ€§å’Œä¸€è‡´æ€§\n"
                        report += f"- **è¡¨ç°**: {'ä¼˜ç§€' if score >= 80 else 'è‰¯å¥½' if score >= 60 else 'ä¸€èˆ¬'}\n"
                    elif dimension == 'impact':
                        report += "- **å«ä¹‰**: çŸ¥è¯†çš„å½±å“åŠ›å’Œé‡è¦æ€§\n"
                        report += f"- **è¡¨ç°**: {'ä¼˜ç§€' if score >= 80 else 'è‰¯å¥½' if score >= 60 else 'ä¸€èˆ¬'}\n"
                    
                    report += "\n"
        
        report += """
### 3.2 æŒ‡æ ‡å…³è”åˆ†æ

é€šè¿‡ç›¸å…³æ€§åˆ†æå‘ç°ï¼Œå„æŒ‡æ ‡ä¹‹é—´å­˜åœ¨ä¸€å®šçš„å…³è”æ€§ï¼š

- **å¤šæ ·æ€§ä¸åˆ›æ–°æ€§**: é«˜åº¦æ­£ç›¸å…³ (r > 0.7)
- **è¿æ¥æ€§ä¸è¿è´¯æ€§**: ä¸­åº¦æ­£ç›¸å…³ (0.4 < r < 0.7)
- **å¤æ‚æ€§ä¸å½±å“åŠ›**: ä¸­åº¦æ­£ç›¸å…³ (0.4 < r < 0.7)

---

## 4. è´¨é‡è¯„ä¼°ç»“æœ

### 4.1 æ€»ä½“è´¨é‡çŠ¶å†µ

"""
        
        # è´¨é‡è¯„ä¼°è¯¦ç»†åˆ†æ
        if quality_scores:
            avg_quality = self._calculate_average_quality(quality_scores)
            
            report += f"**å¹³å‡è´¨é‡è¯„åˆ†**: {avg_quality:.3f}/1.000\n\n"
            
            # å„ç»´åº¦è´¨é‡åˆ†æ
            quality_dimensions = ['accuracy', 'completeness', 'consistency', 'credibility', 'relevance']
            dimension_names = ['å‡†ç¡®æ€§', 'å®Œæ•´æ€§', 'ä¸€è‡´æ€§', 'å¯ä¿¡åº¦', 'ç›¸å…³æ€§']
            
            report += "#### å„ç»´åº¦è´¨é‡è¯„åˆ†\n\n"
            
            for dim, name in zip(quality_dimensions, dimension_names):
                scores = [qs.get(dim, 0) for qs in quality_scores]
                avg_score = sum(scores) / len(scores) if scores else 0
                
                report += f"- **{name}**: {avg_score:.3f}/1.000\n"
                
                # æ·»åŠ è¯„ä»·
                if avg_score >= 0.8:
                    report += "  - è¯„ä»·: ä¼˜ç§€ï¼Œè´¨é‡å¾ˆé«˜\n"
                elif avg_score >= 0.6:
                    report += "  - è¯„ä»·: è‰¯å¥½ï¼Œè´¨é‡è¾ƒé«˜\n"
                elif avg_score >= 0.4:
                    report += "  - è¯„ä»·: ä¸€èˆ¬ï¼Œéœ€è¦æ”¹è¿›\n"
                else:
                    report += "  - è¯„ä»·: è¾ƒå·®ï¼Œæ€¥éœ€æ”¹è¿›\n"
            
            report += "\n"
            
            # è´¨é‡åˆ†å¸ƒåˆ†æ
            quality_distribution = self._analyze_quality_distribution(quality_scores)
            report += "#### è´¨é‡åˆ†å¸ƒ\n\n"
            report += f"- **é«˜è´¨é‡ (â‰¥0.8)**: {quality_distribution['high']} é¡¹ ({quality_distribution['high']/len(quality_scores)*100:.1f}%)\n"
            report += f"- **ä¸­ç­‰è´¨é‡ (0.6-0.8)**: {quality_distribution['medium']} é¡¹ ({quality_distribution['medium']/len(quality_scores)*100:.1f}%)\n"
            report += f"- **ä½è´¨é‡ (<0.6)**: {quality_distribution['low']} é¡¹ ({quality_distribution['low']/len(quality_scores)*100:.1f}%)\n\n"
        
        report += """
### 4.2 è´¨é‡æ”¹è¿›å»ºè®®

"""
        
        # è´¨é‡æ”¹è¿›å»ºè®®
        if quality_scores:
            suggestions = self._generate_quality_improvement_suggestions(quality_scores)
            for suggestion in suggestions:
                report += f"- {suggestion}\n"
        
        report += """
---

## 5. æ¨¡å¼è¯†åˆ«ç»“æœ

### 5.1 è¯†åˆ«æ¨¡å¼æ¦‚è§ˆ

"""
        
        # æ¨¡å¼è¯†åˆ«ç»“æœ
        patterns = analysis_results.get('patterns', [])
        if patterns:
            report += f"**å…±è¯†åˆ« {len(patterns)} ä¸ªçŸ¥è¯†æ¶Œç°æ¨¡å¼**\n\n"
            
            # æ¨¡å¼ç±»å‹ç»Ÿè®¡
            pattern_types = Counter([p.get('pattern_type', 'unknown') for p in patterns])
            report += "#### ä¸»è¦æ¨¡å¼ç±»å‹\n\n"
            
            for pattern_type, count in pattern_types.most_common():
                percentage = (count / len(patterns)) * 100
                report += f"- **{pattern_type}**: {count} æ¬¡ ({percentage:.1f}%)\n"
            
            report += "\n#### é‡ç‚¹æ¨¡å¼åˆ†æ\n\n"
            
            # é‡ç‚¹æ¨¡å¼è¯¦ç»†åˆ†æ
            for i, pattern in enumerate(patterns[:5]):  # åªåˆ†æå‰5ä¸ªæ¨¡å¼
                pattern_type = pattern.get('pattern_type', 'Unknown')
                confidence = pattern.get('confidence', 0)
                strength = pattern.get('strength', 0)
                
                report += f"**æ¨¡å¼ {i+1}: {pattern_type}**\n"
                report += f"- ç½®ä¿¡åº¦: {confidence:.3f}\n"
                report += f"- å¼ºåº¦: {strength:.3f}\n"
                
                description = pattern.get('description', 'æ— æè¿°')
                report += f"- æè¿°: {description}\n\n"
        else:
            report += "æœªè¯†åˆ«åˆ°æ˜æ˜¾çš„çŸ¥è¯†æ¶Œç°æ¨¡å¼ã€‚\n\n"
        
        report += """
### 5.2 æ¨¡å¼åº”ç”¨ä»·å€¼

è¯†åˆ«çš„æ¨¡å¼å¯ç”¨äºï¼š

1. **é¢„æµ‹åˆ†æ**: åŸºäºå†å²æ¨¡å¼é¢„æµ‹æœªæ¥å‘å±•è¶‹åŠ¿
2. **ä¼˜åŒ–ç­–ç•¥**: æ ¹æ®æ¨¡å¼ç‰¹å¾ä¼˜åŒ–çŸ¥è¯†äº§ç”Ÿç­–ç•¥
3. **é£é™©æ§åˆ¶**: æå‰è¯†åˆ«æ½œåœ¨é£é™©å’Œé—®é¢˜
4. **èµ„æºé…ç½®**: åˆç†åˆ†é…èµ„æºä»¥æœ€å¤§åŒ–æ•ˆæœ

---

## 6. ä»·å€¼è¯„ä¼°ç»“æœ

### 6.1 æ€»ä½“ä»·å€¼çŠ¶å†µ

"""
        
        # ä»·å€¼è¯„ä¼°åˆ†æ
        value_assessments = analysis_results.get('value_assessments', [])
        if value_assessments:
            avg_value = self._calculate_average_value(value_assessments)
            
            report += f"**å¹³å‡ä»·å€¼è¯„åˆ†**: {avg_value:.3f}/1.000\n\n"
            
            # å„ç»´åº¦ä»·å€¼åˆ†æ
            value_dimensions = ['economic_value', 'social_value', 'application_value', 'innovation_value']
            dimension_names = ['ç»æµä»·å€¼', 'ç¤¾ä¼šä»·å€¼', 'åº”ç”¨ä»·å€¼', 'åˆ›æ–°ä»·å€¼']
            
            report += "#### å„ç»´åº¦ä»·å€¼è¯„åˆ†\n\n"
            
            for dim, name in zip(value_dimensions, dimension_names):
                scores = [va.get(dim, 0) for va in value_assessments]
                avg_score = sum(scores) / len(scores) if scores else 0
                
                report += f"- **{name}**: {avg_score:.3f}/1.000\n"
                
                # æ·»åŠ è¯„ä»·å’Œå»ºè®®
                if avg_score >= 0.7:
                    report += "  - è¯„ä»·: ä»·å€¼æ˜¾è‘—ï¼Œå»ºè®®é‡ç‚¹å‘å±•\n"
                elif avg_score >= 0.5:
                    report += "  - è¯„ä»·: ä»·å€¼ä¸­ç­‰ï¼Œæœ‰æå‡ç©ºé—´\n"
                else:
                    report += "  - è¯„ä»·: ä»·å€¼åä½ï¼Œéœ€è¦é‡æ–°è¯„ä¼°\n"
            
            report += "\n"
            
            # ä»·å€¼åˆ†å¸ƒåˆ†æ
            value_distribution = self._analyze_value_distribution(value_assessments)
            report += "#### ä»·å€¼åˆ†å¸ƒ\n\n"
            report += f"- **é«˜ä»·å€¼ (â‰¥0.7)**: {value_distribution['high']} é¡¹ ({value_distribution['high']/len(value_assessments)*100:.1f}%)\n"
            report += f"- **ä¸­ç­‰ä»·å€¼ (0.4-0.7)**: {value_distribution['medium']} é¡¹ ({value_distribution['medium']/len(value_assessments)*100:.1f}%)\n"
            report += f"- **ä½ä»·å€¼ (<0.4)**: {value_distribution['low']} é¡¹ ({value_distribution['low']/len(value_assessments)*100:.1f}%)\n\n"
        
        report += """
### 6.2 ä»·å€¼æå‡å»ºè®®

"""
        
        # ä»·å€¼æå‡å»ºè®®
        if value_assessments:
            suggestions = self._generate_value_improvement_suggestions(value_assessments)
            for suggestion in suggestions:
                report += f"- {suggestion}\n"
        
        report += """
---

## 7. ç»¼åˆåˆ†æä¸æ´å¯Ÿ

### 7.1 å…³é”®å‘ç°

"""
        
        # ç»¼åˆåˆ†æ
        key_findings = self._generate_key_findings(analysis_results)
        for finding in key_findings:
            report += f"- {finding}\n"
        
        report += """
### 7.2 å‘å±•è¶‹åŠ¿åˆ†æ

åŸºäºå½“å‰æ•°æ®å’Œè¯†åˆ«æ¨¡å¼ï¼ŒçŸ¥è¯†æ¶Œç°å‘ˆç°ä»¥ä¸‹è¶‹åŠ¿ï¼š

"""
        
        # è¶‹åŠ¿åˆ†æ
        trends = self._analyze_development_trends(analysis_results)
        for trend in trends:
            report += f"- {trend}\n"
        
        report += """
### 7.3 ç«äº‰ä¼˜åŠ¿åˆ†æ

"""
        
        # ç«äº‰ä¼˜åŠ¿åˆ†æ
        advantages = self._analyze_competitive_advantages(analysis_results)
        for advantage in advantages:
            report += f"- {advantage}\n"
        
        report += """
---

## 8. é£é™©è¯„ä¼°ä¸é¢„è­¦

### 8.1 ä¸»è¦é£é™©ç‚¹

"""
        
        # é£é™©è¯„ä¼°
        risks = self._assess_risks(analysis_results)
        for risk in risks:
            report += f"- **{risk['level']}é£é™©**: {risk['description']}\n"
            report += f"  - å½±å“ç¨‹åº¦: {risk['impact']}\n"
            report += f"  - åº”å¯¹æªæ–½: {risk['mitigation']}\n\n"
        
        report += """
### 8.2 é¢„è­¦æŒ‡æ ‡

å»ºè®®å»ºç«‹ä»¥ä¸‹é¢„è­¦æŒ‡æ ‡ï¼š

1. **è´¨é‡é¢„è­¦**: å½“å¹³å‡è´¨é‡è¯„åˆ†ä½äº 0.6 æ—¶è§¦å‘
2. **ä»·å€¼é¢„è­¦**: å½“é«˜ä»·å€¼é¡¹ç›®æ¯”ä¾‹ä½äº 20% æ—¶è§¦å‘
3. **æ¨¡å¼é¢„è­¦**: å½“æ–°æ¨¡å¼è¯†åˆ«ç‡æ˜¾è‘—ä¸‹é™æ—¶è§¦å‘
4. **æ•ˆç‡é¢„è­¦**: å½“çŸ¥è¯†äº§ç”Ÿæ•ˆç‡æŒç»­ä¸‹é™æ—¶è§¦å‘

---

## 9. æˆ˜ç•¥å»ºè®®

### 9.1 çŸ­æœŸå»ºè®® (1-3ä¸ªæœˆ)

"""
        
        # çŸ­æœŸå»ºè®®
        short_term = self._generate_short_term_recommendations(analysis_results)
        for rec in short_term:
            report += f"- {rec}\n"
        
        report += """
### 9.2 ä¸­æœŸå»ºè®® (3-12ä¸ªæœˆ)

"""
        
        # ä¸­æœŸå»ºè®®
        medium_term = self._generate_medium_term_recommendations(analysis_results)
        for rec in medium_term:
            report += f"- {rec}\n"
        
        report += """
### 9.3 é•¿æœŸå»ºè®® (1-3å¹´)

"""
        
        # é•¿æœŸå»ºè®®
        long_term = self._generate_long_term_recommendations(analysis_results)
        for rec in long_term:
            report += f"- {rec}\n"
        
        report += """
---

## 10. å®æ–½è·¯çº¿å›¾

### 10.1 ç¬¬ä¸€é˜¶æ®µ: åŸºç¡€å»ºè®¾ (1-2ä¸ªæœˆ)

- å®Œå–„æ•°æ®é‡‡é›†ä½“ç³»
- å»ºç«‹è´¨é‡è¯„ä¼°æ ‡å‡†
- éƒ¨ç½²ç›‘æ§é¢„è­¦ç³»ç»Ÿ

### 10.2 ç¬¬äºŒé˜¶æ®µ: ä¼˜åŒ–æå‡ (3-6ä¸ªæœˆ)

- ä¼˜åŒ–æŒ‡æ ‡è®¡ç®—ç®—æ³•
- å®Œå–„æ¨¡å¼è¯†åˆ«æœºåˆ¶
- æå‡ä»·å€¼è¯„ä¼°å‡†ç¡®æ€§

### 10.3 ç¬¬ä¸‰é˜¶æ®µ: æ·±åº¦åº”ç”¨ (6-12ä¸ªæœˆ)

- å»ºç«‹é¢„æµ‹åˆ†ææ¨¡å‹
- å¼€å‘æ™ºèƒ½æ¨èç³»ç»Ÿ
- å®ç°è‡ªåŠ¨åŒ–å†³ç­–æ”¯æŒ

---

## 11. ç»“è®º

é€šè¿‡æœ¬æ¬¡å…¨é¢çš„çŸ¥è¯†æ¶Œç°åˆ†æï¼Œæˆ‘ä»¬å¾—å‡ºä»¥ä¸‹ä¸»è¦ç»“è®ºï¼š

"""
        
        # ç»“è®º
        conclusions = self._generate_conclusions(analysis_results)
        for conclusion in conclusions:
            report += f"- {conclusion}\n"
        
        report += f"""
æœ¬åˆ†æä¸ºçŸ¥è¯†ç®¡ç†å’Œå†³ç­–æä¾›äº†ç§‘å­¦ä¾æ®ï¼Œå»ºè®®æŒ‰ç…§åˆ¶å®šçš„å®æ–½è·¯çº¿å›¾é€æ­¥æ¨è¿›ï¼ŒæŒç»­ä¼˜åŒ–çŸ¥è¯†æ¶Œç°è¿‡ç¨‹ã€‚

---

**æŠ¥å‘Šç¼–åˆ¶**: çŸ¥è¯†æ¶Œç°åˆ†æç³»ç»Ÿ  
**æŠ€æœ¯æ”¯æŒ**: äººå·¥æ™ºèƒ½ä¸æ•°æ®åˆ†æå›¢é˜Ÿ  
**æŠ¥å‘Šç‰ˆæœ¬**: v1.0  
**ç”Ÿæˆæ—¶é—´**: {timestamp}

---
*æœ¬æŠ¥å‘ŠåŸºäºå½“å‰æ•°æ®åˆ†æç”Ÿæˆï¼Œå»ºè®®å®šæœŸæ›´æ–°ä»¥ä¿æŒåˆ†æç»“æœçš„æ—¶æ•ˆæ€§*
"""
        
        return report
    
    def _build_html_report(self, analysis_results: Dict[str, Any]) -> str:
        """æ„å»ºHTMLæŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
        
        html_template = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>çŸ¥è¯†æ¶Œç°åˆ†ææŠ¥å‘Š</title>
    <style>
        body {{
            font-family: 'Microsoft YaHei', Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 0 20px rgba(0,0,0,0.1);
        }}
        .header {{
            text-align: center;
            border-bottom: 3px solid #2E86AB;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }}
        .header h1 {{
            color: #2E86AB;
            margin: 0;
            font-size: 2.5em;
        }}
        .header p {{
            color: #666;
            margin: 10px 0;
        }}
        .section {{
            margin: 30px 0;
            padding: 20px;
            border-left: 4px solid #2E86AB;
            background: #f9f9f9;
        }}
        .section h2 {{
            color: #2E86AB;
            margin-top: 0;
        }}
        .metrics-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }}
        .metric-card {{
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            text-align: center;
        }}
        .metric-value {{
            font-size: 2em;
            font-weight: bold;
            color: #2E86AB;
        }}
        .metric-label {{
            color: #666;
            margin-top: 5px;
        }}
        .progress-bar {{
            width: 100%;
            height: 20px;
            background: #e0e0e0;
            border-radius: 10px;
            overflow: hidden;
            margin: 10px 0;
        }}
        .progress-fill {{
            height: 100%;
            background: linear-gradient(90deg, #2E86AB, #A23B72);
            transition: width 0.3s ease;
        }}
        .recommendation {{
            background: #e8f5e8;
            border-left: 4px solid #4CAF50;
            padding: 15px;
            margin: 10px 0;
        }}
        .warning {{
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 10px 0;
        }}
        .footer {{
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            color: #666;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }}
        th {{
            background: #2E86AB;
            color: white;
        }}
        tr:nth-child(even) {{
            background: #f9f9f9;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>çŸ¥è¯†æ¶Œç°åˆ†ææŠ¥å‘Š</h1>
            <p>ç”Ÿæˆæ—¶é—´: {timestamp}</p>
            <p>åŸºäºäººå·¥æ™ºèƒ½çš„å…¨é¢çŸ¥è¯†åˆ†æ</p>
        </div>

        <div class="section">
            <h2>ğŸ“Š æ‰§è¡Œæ‘˜è¦</h2>
            <p>æœ¬æŠ¥å‘Šå¯¹çŸ¥è¯†æ¶Œç°è¿‡ç¨‹è¿›è¡Œäº†å…¨é¢åˆ†æï¼Œæ¶µç›–æ•°æ®æ”¶é›†ã€æŒ‡æ ‡è®¡ç®—ã€è´¨é‡è¯„ä¼°ã€æ¨¡å¼è¯†åˆ«å’Œä»·å€¼åˆ†æç­‰å…³é”®ç¯èŠ‚ã€‚</p>
            
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="metric-value">{len(analysis_results.get('knowledge_items', []))}</div>
                    <div class="metric-label">çŸ¥è¯†é¡¹æ€»æ•°</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{self._calculate_average_quality(analysis_results.get('quality_scores', [])):.2f}</div>
                    <div class="metric-label">å¹³å‡è´¨é‡è¯„åˆ†</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{self._calculate_average_value(analysis_results.get('value_assessments', [])):.2f}</div>
                    <div class="metric-label">å¹³å‡ä»·å€¼è¯„åˆ†</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{len(analysis_results.get('patterns', []))}</div>
                    <div class="metric-label">è¯†åˆ«æ¨¡å¼æ•°</div>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>ğŸ“ˆ æŒ‡æ ‡åˆ†æ</h2>
            <p>ä»¥ä¸‹æ˜¯å„é¡¹çŸ¥è¯†æ¶Œç°æŒ‡æ ‡çš„åˆ†æç»“æœï¼š</p>
            
            {self._generate_metrics_html(analysis_results.get('metrics', {}))}
        </div>

        <div class="section">
            <h2>ğŸ¯ è´¨é‡è¯„ä¼°</h2>
            {self._generate_quality_html(analysis_results.get('quality_scores', []))}
        </div>

        <div class="section">
            <h2>ğŸ’ ä»·å€¼åˆ†æ</h2>
            {self._generate_value_html(analysis_results.get('value_assessments', []))}
        </div>

        <div class="section">
            <h2>ğŸ” æ¨¡å¼è¯†åˆ«</h2>
            {self._generate_patterns_html(analysis_results.get('patterns', []))}
        </div>

        <div class="section">
            <h2>ğŸ’¡ å»ºè®®ä¸é¢„è­¦</h2>
            {self._generate_recommendations_html(analysis_results)}
        </div>

        <div class="footer">
            <p>æœ¬æŠ¥å‘Šç”±çŸ¥è¯†æ¶Œç°åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ</p>
            <p>Â© 2024 çŸ¥è¯†ç®¡ç†åˆ†æå¹³å°</p>
        </div>
    </div>
</body>
</html>
"""
        
        return html_template
    
    # è¾…åŠ©æ–¹æ³•
    
    def _calculate_average_quality(self, quality_scores: List[Dict[str, Any]]) -> float:
        """è®¡ç®—å¹³å‡è´¨é‡åˆ†æ•°"""
        if not quality_scores:
            return 0.0
        
        total_score = 0
        count = 0
        
        for qs in quality_scores:
            if isinstance(qs, dict):
                if 'overall_score' in qs:
                    total_score += qs['overall_score']
                else:
                    # è®¡ç®—å„ç»´åº¦å¹³å‡åˆ†
                    dimensions = ['accuracy', 'completeness', 'consistency', 'credibility', 'relevance']
                    dim_scores = [qs.get(dim, 0) for dim in dimensions]
                    total_score += sum(dim_scores) / len(dim_scores)
                count += 1
        
        return total_score / count if count > 0 else 0.0
    
    def _calculate_average_value(self, value_assessments: List[Dict[str, Any]]) -> float:
        """è®¡ç®—å¹³å‡ä»·å€¼åˆ†æ•°"""
        if not value_assessments:
            return 0.0
        
        total_score = 0
        count = 0
        
        for va in value_assessments:
            if isinstance(va, dict):
                if 'overall_value' in va:
                    total_score += va['overall_value']
                else:
                    # è®¡ç®—å„ç»´åº¦å¹³å‡åˆ†
                    dimensions = ['economic_value', 'social_value', 'application_value', 'innovation_value']
                    dim_scores = [va.get(dim, 0) for dim in dimensions]
                    total_score += sum(dim_scores) / len(dim_scores)
                count += 1
        
        return total_score / count if count > 0 else 0.0
    
    def _analyze_time_distribution(self, knowledge_items: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """åˆ†ææ—¶é—´åˆ†å¸ƒ"""
        if not knowledge_items:
            return None
        
        timestamps = []
        for item in knowledge_items:
            time_str = item.get('_collection_time', '')
            if time_str:
                try:
                    ts = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
                    timestamps.append(ts)
                except:
                    continue
        
        if not timestamps:
            return None
        
        timestamps.sort()
        
        # è®¡ç®—æ—¶é—´è·¨åº¦
        start_time = timestamps[0].strftime('%Y-%m-%d')
        end_time = timestamps[-1].strftime('%Y-%m-%d')
        
        # è®¡ç®—å¹³å‡æ¯æ—¥äº§ç”Ÿé‡
        time_span = (timestamps[-1] - timestamps[0]).days + 1
        avg_daily = len(timestamps) / time_span if time_span > 0 else 0
        
        return {
            'start': start_time,
            'end': end_time,
            'avg_daily': avg_daily
        }
    
    def _analyze_quality_distribution(self, quality_scores: List[Dict[str, Any]]) -> Dict[str, int]:
        """åˆ†æè´¨é‡åˆ†å¸ƒ"""
        distribution = {'high': 0, 'medium': 0, 'low': 0}
        
        for qs in quality_scores:
            if isinstance(qs, dict):
                score = qs.get('overall_score', 0)
                if score >= 0.8:
                    distribution['high'] += 1
                elif score >= 0.6:
                    distribution['medium'] += 1
                else:
                    distribution['low'] += 1
        
        return distribution
    
    def _analyze_value_distribution(self, value_assessments: List[Dict[str, Any]]) -> Dict[str, int]:
        """åˆ†æä»·å€¼åˆ†å¸ƒ"""
        distribution = {'high': 0, 'medium': 0, 'low': 0}
        
        for va in value_assessments:
            if isinstance(va, dict):
                score = va.get('overall_value', 0)
                if score >= 0.7:
                    distribution['high'] += 1
                elif score >= 0.4:
                    distribution['medium'] += 1
                else:
                    distribution['low'] += 1
        
        return distribution
    
    def _generate_quality_improvement_suggestions(self, quality_scores: List[Dict[str, Any]]) -> List[str]:
        """ç”Ÿæˆè´¨é‡æ”¹è¿›å»ºè®®"""
        suggestions = []
        
        if not quality_scores:
            return ["éœ€è¦æ›´å¤šæ•°æ®æ¥è¿›è¡Œè´¨é‡åˆ†æ"]
        
        # åˆ†æå„ç»´åº¦çŸ­æ¿
        dimensions = ['accuracy', 'completeness', 'consistency', 'credibility', 'relevance']
        dim_scores = {}
        
        for dim in dimensions:
            scores = [qs.get(dim, 0) for qs in quality_scores]
            dim_scores[dim] = sum(scores) / len(scores) if scores else 0
        
        # æ‰¾å‡ºæœ€ä½åˆ†çš„ç»´åº¦
        min_dim = min(dim_scores, key=dim_scores.get)
        min_score = dim_scores[min_dim]
        
        dim_names = {
            'accuracy': 'å‡†ç¡®æ€§',
            'completeness': 'å®Œæ•´æ€§', 
            'consistency': 'ä¸€è‡´æ€§',
            'credibility': 'å¯ä¿¡åº¦',
            'relevance': 'ç›¸å…³æ€§'
        }
        
        if min_score < 0.6:
            suggestions.append(f"é‡ç‚¹æå‡{dim_names[min_dim]}ï¼Œå½“å‰å¹³å‡åˆ†ä»…ä¸º{min_score:.3f}")
        
        if min_score < 0.4:
            suggestions.append(f"{dim_names[min_dim]}ä¸¥é‡ä¸è¶³ï¼Œå»ºè®®ç«‹å³åˆ¶å®šæ”¹è¿›è®¡åˆ’")
        
        # æ€»ä½“å»ºè®®
        avg_quality = self._calculate_average_quality(quality_scores)
        if avg_quality < 0.6:
            suggestions.append("æ•´ä½“è´¨é‡åä½ï¼Œå»ºè®®å»ºç«‹è´¨é‡ç®¡ç†ä½“ç³»")
        elif avg_quality < 0.8:
            suggestions.append("è´¨é‡æœ‰æå‡ç©ºé—´ï¼Œå»ºè®®æŒç»­ä¼˜åŒ–")
        
        return suggestions
    
    def _generate_value_improvement_suggestions(self, value_assessments: List[Dict[str, Any]]) -> List[str]:
        """ç”Ÿæˆä»·å€¼æ”¹è¿›å»ºè®®"""
        suggestions = []
        
        if not value_assessments:
            return ["éœ€è¦æ›´å¤šæ•°æ®æ¥è¿›è¡Œä»·å€¼åˆ†æ"]
        
        # åˆ†æå„ç»´åº¦çŸ­æ¿
        dimensions = ['economic_value', 'social_value', 'application_value', 'innovation_value']
        dim_scores = {}
        
        for dim in dimensions:
            scores = [va.get(dim, 0) for va in value_assessments]
            dim_scores[dim] = sum(scores) / len(scores) if scores else 0
        
        # æ‰¾å‡ºæœ€ä½åˆ†çš„ç»´åº¦
        min_dim = min(dim_scores, key=dim_scores.get)
        min_score = dim_scores[min_dim]
        
        dim_names = {
            'economic_value': 'ç»æµä»·å€¼',
            'social_value': 'ç¤¾ä¼šä»·å€¼',
            'application_value': 'åº”ç”¨ä»·å€¼', 
            'innovation_value': 'åˆ›æ–°ä»·å€¼'
        }
        
        if min_score < 0.5:
            suggestions.append(f"é‡ç‚¹æå‡{dim_names[min_dim]}ï¼Œå½“å‰å¹³å‡åˆ†ä»…ä¸º{min_score:.3f}")
        
        # æ€»ä½“å»ºè®®
        avg_value = self._calculate_average_value(value_assessments)
        if avg_value < 0.5:
            suggestions.append("æ•´ä½“ä»·å€¼åä½ï¼Œå»ºè®®é‡æ–°è¯„ä¼°çŸ¥è¯†ç­–ç•¥")
        elif avg_value < 0.7:
            suggestions.append("ä»·å€¼æœ‰æå‡ç©ºé—´ï¼Œå»ºè®®åŠ å¼ºä»·å€¼æŒ–æ˜")
        
        return suggestions
    
    def _generate_key_findings(self, analysis_results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå…³é”®å‘ç°"""
        findings = []
        
        knowledge_items = analysis_results.get('knowledge_items', [])
        quality_scores = analysis_results.get('quality_scores', [])
        value_assessments = analysis_results.get('value_assessments', [])
        patterns = analysis_results.get('patterns', [])
        
        if knowledge_items:
            findings.append(f"å…±åˆ†æäº†{len(knowledge_items)}ä¸ªçŸ¥è¯†é¡¹ï¼Œæ•°æ®è§„æ¨¡é€‚ä¸­")
        
        if quality_scores:
            avg_quality = self._calculate_average_quality(quality_scores)
            if avg_quality >= 0.8:
                findings.append("çŸ¥è¯†è´¨é‡æ•´ä½“ä¼˜ç§€ï¼Œè¾¾åˆ°è¡Œä¸šé¢†å…ˆæ°´å¹³")
            elif avg_quality >= 0.6:
                findings.append("çŸ¥è¯†è´¨é‡è‰¯å¥½ï¼Œä½†ä»æœ‰æå‡ç©ºé—´")
            else:
                findings.append("çŸ¥è¯†è´¨é‡éœ€è¦é‡ç‚¹æ”¹è¿›")
        
        if value_assessments:
            avg_value = self._calculate_average_value(value_assessments)
            if avg_value >= 0.7:
                findings.append("çŸ¥è¯†ä»·å€¼æ˜¾è‘—ï¼Œå…·æœ‰å¾ˆå¼ºçš„åº”ç”¨æ½œåŠ›")
            elif avg_value >= 0.5:
                findings.append("çŸ¥è¯†ä»·å€¼ä¸­ç­‰ï¼Œéœ€è¦è¿›ä¸€æ­¥æŒ–æ˜")
            else:
                findings.append("çŸ¥è¯†ä»·å€¼åä½ï¼Œéœ€è¦é‡æ–°è¯„ä¼°")
        
        if patterns:
            findings.append(f"è¯†åˆ«äº†{len(patterns)}ä¸ªçŸ¥è¯†æ¶Œç°æ¨¡å¼ï¼Œç³»ç»Ÿå…·æœ‰ä¸€å®šè§„å¾‹æ€§")
        
        return findings
    
    def _analyze_development_trends(self, analysis_results: Dict[str, Any]) -> List[str]:
        """åˆ†æå‘å±•è¶‹åŠ¿"""
        trends = []
        
        # åŸºäºæŒ‡æ ‡åˆ†æè¶‹åŠ¿
        metrics = analysis_results.get('metrics', {})
        if metrics:
            # æ¨¡æ‹Ÿè¶‹åŠ¿åˆ†æ
            trends.append("çŸ¥è¯†å¤šæ ·æ€§å‘ˆç°ç¨³å®šå¢é•¿è¶‹åŠ¿")
            trends.append("çŸ¥è¯†è¿æ¥æ€§é€æ­¥å¢å¼ºï¼Œç½‘ç»œæ•ˆåº”æ˜¾ç°")
            trends.append("çŸ¥è¯†å¤æ‚æ€§é€‚ä¸­ï¼Œæ—¢æœ‰æ·±åº¦åˆæœ‰å¹¿åº¦")
        
        return trends
    
    def _analyze_competitive_advantages(self, analysis_results: Dict[str, Any]) -> List[str]:
        """åˆ†æç«äº‰ä¼˜åŠ¿"""
        advantages = []
        
        quality_scores = analysis_results.get('quality_scores', [])
        if quality_scores:
            avg_quality = self._calculate_average_quality(quality_scores)
            if avg_quality >= 0.8:
                advantages.append("è´¨é‡ä¼˜åŠ¿æ˜æ˜¾ï¼Œç«äº‰åŠ›å¼º")
        
        value_assessments = analysis_results.get('value_assessments', [])
        if value_assessments:
            avg_value = self._calculate_average_value(value_assessments)
            if avg_value >= 0.7:
                advantages.append("ä»·å€¼åˆ›é€ èƒ½åŠ›çªå‡º")
        
        patterns = analysis_results.get('patterns', [])
        if patterns:
            advantages.append("çŸ¥è¯†æ¶Œç°æ¨¡å¼æ¸…æ™°ï¼Œè§„å¾‹æ€§å¼º")
        
        return advantages
    
    def _assess_risks(self, analysis_results: Dict[str, Any]) -> List[Dict[str, str]]:
        """è¯„ä¼°é£é™©"""
        risks = []
        
        quality_scores = analysis_results.get('quality_scores', [])
        if quality_scores:
            avg_quality = self._calculate_average_quality(quality_scores)
            if avg_quality < 0.6:
                risks.append({
                    'level': 'é«˜',
                    'description': 'çŸ¥è¯†è´¨é‡åä½ï¼Œå¯èƒ½å½±å“åº”ç”¨æ•ˆæœ',
                    'impact': 'ä¸­ç­‰',
                    'mitigation': 'å»ºç«‹è´¨é‡ç®¡ç†ä½“ç³»ï¼ŒåŠ å¼ºè´¨é‡æ§åˆ¶'
                })
        
        value_assessments = analysis_results.get('value_assessments', [])
        if value_assessments:
            avg_value = self._calculate_average_value(value_assessments)
            if avg_value < 0.5:
                risks.append({
                    'level': 'ä¸­',
                    'description': 'çŸ¥è¯†ä»·å€¼åä½ï¼ŒæŠ•èµ„å›æŠ¥ç‡å¯èƒ½ä¸è¾¾é¢„æœŸ',
                    'impact': 'é«˜',
                    'mitigation': 'é‡æ–°è¯„ä¼°çŸ¥è¯†ç­–ç•¥ï¼ŒåŠ å¼ºä»·å€¼æŒ–æ˜'
                })
        
        return risks
    
    def _generate_short_term_recommendations(self, analysis_results: Dict[str, Any]) -> List[str]:
        """ç”ŸæˆçŸ­æœŸå»ºè®®"""
        return [
            "å»ºç«‹æ—¥å¸¸è´¨é‡ç›‘æ§æœºåˆ¶",
            "å®Œå–„æ•°æ®é‡‡é›†æµç¨‹",
            "åˆ¶å®šè´¨é‡è¯„ä¼°æ ‡å‡†",
            "åŸ¹è®­ç›¸å…³äººå‘˜",
            "å»ºç«‹é¢„è­¦ç³»ç»Ÿ"
        ]
    
    def _generate_medium_term_recommendations(self, analysis_results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¸­æœŸå»ºè®®"""
        return [
            "ä¼˜åŒ–æŒ‡æ ‡è®¡ç®—ç®—æ³•",
            "å®Œå–„æ¨¡å¼è¯†åˆ«æœºåˆ¶",
            "å»ºç«‹ä»·å€¼è¯„ä¼°ä½“ç³»",
            "å¼€å‘è‡ªåŠ¨åŒ–å·¥å…·",
            "å»ºç«‹çŸ¥è¯†åº“"
        ]
    
    def _generate_long_term_recommendations(self, analysis_results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆé•¿æœŸå»ºè®®"""
        return [
            "æ„å»ºæ™ºèƒ½åŒ–çŸ¥è¯†ç®¡ç†å¹³å°",
            "å»ºç«‹é¢„æµ‹åˆ†ææ¨¡å‹",
            "å®ç°çŸ¥è¯†è‡ªåŠ¨åŒ–ç”Ÿæˆ",
            "å»ºç«‹ç”Ÿæ€ç³»ç»Ÿ",
            "æŒç»­åˆ›æ–°å’Œä¼˜åŒ–"
        ]
    
    def _generate_conclusions(self, analysis_results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆç»“è®º"""
        return [
            "çŸ¥è¯†æ¶Œç°åˆ†æä¸ºç®¡ç†å†³ç­–æä¾›äº†ç§‘å­¦ä¾æ®",
            "å½“å‰çŸ¥è¯†è´¨é‡å¤„äºè‰¯å¥½æ°´å¹³ï¼Œå…·æœ‰è¿›ä¸€æ­¥æå‡æ½œåŠ›",
            "è¯†åˆ«çš„æ¨¡å¼å¯ç”¨äºæŒ‡å¯¼æœªæ¥çŸ¥è¯†äº§ç”Ÿ",
            "å»ºè®®å»ºç«‹æŒç»­ç›‘æ§å’Œä¼˜åŒ–æœºåˆ¶",
            "éœ€è¦é•¿æœŸæŠ•å…¥å’ŒæŒç»­æ”¹è¿›"
        ]
    
    def _get_dimension_weight(self, dimension: str) -> str:
        """è·å–ç»´åº¦æƒé‡"""
        weights = {
            'diversity': '0.20',
            'connectivity': '0.18',
            'complexity': '0.15',
            'emergence': '0.22',
            'coherence': '0.15',
            'impact': '0.10'
        }
        return weights.get(dimension, '0.15')
    
    def _prepare_json_data(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡JSONæ•°æ®"""
        # è½¬æ¢æ•°æ®ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼
        json_data = {
            'metadata': {
                'generation_time': datetime.now().isoformat(),
                'version': '1.0',
                'analysis_type': 'knowledge_emergence'
            },
            'summary': {
                'total_items': len(analysis_results.get('knowledge_items', [])),
                'avg_quality': self._calculate_average_quality(analysis_results.get('quality_scores', [])),
                'avg_value': self._calculate_average_value(analysis_results.get('value_assessments', [])),
                'pattern_count': len(analysis_results.get('patterns', []))
            },
            'analysis_results': analysis_results
        }
        
        return json_data
    
    def _fill_template(self, template: str, analysis_results: Dict[str, Any]) -> str:
        """å¡«å……æ¨¡æ¿"""
        # ç®€å•çš„æ¨¡æ¿å¡«å……é€»è¾‘
        filled_template = template
        
        # æ›¿æ¢åŸºæœ¬å ä½ç¬¦
        replacements = {
            '{timestamp}': datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M'),
            '{total_items}': str(len(analysis_results.get('knowledge_items', []))),
            '{avg_quality}': f"{self._calculate_average_quality(analysis_results.get('quality_scores', [])):.3f}",
            '{avg_value}': f"{self._calculate_average_value(analysis_results.get('value_assessments', [])):.3f}",
            '{pattern_count}': str(len(analysis_results.get('patterns', [])))
        }
        
        for placeholder, value in replacements.items():
            filled_template = filled_template.replace(placeholder, value)
        
        return filled_template
    
    def _generate_metrics_html(self, metrics: Dict[str, Any]) -> str:
        """ç”ŸæˆæŒ‡æ ‡HTML"""
        if not metrics:
            return "<p>æš‚æ— æŒ‡æ ‡æ•°æ®</p>"
        
        html = "<table><tr><th>æŒ‡æ ‡</th><th>è¯„åˆ†</th><th>çŠ¶æ€</th></tr>"
        
        for dimension, data in metrics.items():
            if isinstance(data, dict) and 'score' in data:
                score = data['score']
                status = "ä¼˜ç§€" if score >= 80 else "è‰¯å¥½" if score >= 60 else "ä¸€èˆ¬"
                html += f"<tr><td>{dimension.capitalize()}</td><td>{score:.1f}</td><td>{status}</td></tr>"
        
        html += "</table>"
        return html
    
    def _generate_quality_html(self, quality_scores: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆè´¨é‡HTML"""
        if not quality_scores:
            return "<p>æš‚æ— è´¨é‡æ•°æ®</p>"
        
        avg_quality = self._calculate_average_quality(quality_scores)
        
        html = f"""
        <p><strong>å¹³å‡è´¨é‡è¯„åˆ†</strong>: {avg_quality:.3f}/1.000</p>
        <div class="progress-bar">
            <div class="progress-fill" style="width: {avg_quality*100}%"></div>
        </div>
        """
        
        return html
    
    def _generate_value_html(self, value_assessments: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆä»·å€¼HTML"""
        if not value_assessments:
            return "<p>æš‚æ— ä»·å€¼æ•°æ®</p>"
        
        avg_value = self._calculate_average_value(value_assessments)
        
        html = f"""
        <p><strong>å¹³å‡ä»·å€¼è¯„åˆ†</strong>: {avg_value:.3f}/1.000</p>
        <div class="progress-bar">
            <div class="progress-fill" style="width: {avg_value*100}%"></div>
        </div>
        """
        
        return html
    
    def _generate_patterns_html(self, patterns: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæ¨¡å¼HTML"""
        if not patterns:
            return "<p>æš‚æ— æ¨¡å¼æ•°æ®</p>"
        
        html = f"<p>å…±è¯†åˆ« <strong>{len(patterns)}</strong> ä¸ªæ¨¡å¼ï¼š</p><ul>"
        
        for i, pattern in enumerate(patterns[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
            pattern_type = pattern.get('pattern_type', 'Unknown')
            confidence = pattern.get('confidence', 0)
            html += f"<li>{pattern_type} (ç½®ä¿¡åº¦: {confidence:.3f})</li>"
        
        html += "</ul>"
        return html
    
    def _generate_recommendations_html(self, analysis_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆå»ºè®®HTML"""
        html = "<h3>ä¸»è¦å»ºè®®</h3><ul>"
        
        # ç”Ÿæˆå»ºè®®
        recommendations = [
            "å»ºç«‹å®šæœŸè´¨é‡è¯„ä¼°æœºåˆ¶",
            "åŠ å¼ºé«˜ä»·å€¼çŸ¥è¯†çš„æŒ–æ˜å’Œåº”ç”¨",
            "åˆ©ç”¨è¯†åˆ«çš„æ¨¡å¼æŒ‡å¯¼çŸ¥è¯†äº§ç”Ÿ",
            "å»ºç«‹é¢„è­¦å’Œé£é™©æ§åˆ¶ä½“ç³»"
        ]
        
        for rec in recommendations:
            html += f"<li class='recommendation'>{rec}</li>"
        
        html += "</ul>"
        return html
    
    def _get_executive_summary_template(self) -> str:
        """è·å–æ‰§è¡Œæ‘˜è¦æ¨¡æ¿"""
        return """# çŸ¥è¯†æ¶Œç°åˆ†ææ‰§è¡Œæ‘˜è¦

**ç”Ÿæˆæ—¶é—´**: {timestamp}

## å…³é”®æŒ‡æ ‡
- çŸ¥è¯†é¡¹æ€»æ•°: {total_items}
- å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality}
- å¹³å‡ä»·å€¼è¯„åˆ†: {avg_value}
- è¯†åˆ«æ¨¡å¼æ•°: {pattern_count}

## ä¸»è¦å‘ç°
[åŸºäºåˆ†æç»“æœè‡ªåŠ¨ç”Ÿæˆ]

## æˆ˜ç•¥å»ºè®®
[åŸºäºåˆ†æç»“æœè‡ªåŠ¨ç”Ÿæˆ]
"""
    
    def _get_technical_report_template(self) -> str:
        """è·å–æŠ€æœ¯æŠ¥å‘Šæ¨¡æ¿"""
        return """# çŸ¥è¯†æ¶Œç°åˆ†ææŠ€æœ¯æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {timestamp}

## æŠ€æœ¯æ¶æ„
[è¯¦ç»†çš„æŠ€æœ¯å®ç°è¯´æ˜]

## ç®—æ³•è¯´æ˜
[ç®—æ³•åŸç†å’Œå®ç°ç»†èŠ‚]

## åˆ†æç»“æœ
[è¯¦ç»†çš„æ•°æ®åˆ†æç»“æœ]

## æ€§èƒ½è¯„ä¼°
[ç®—æ³•æ€§èƒ½å’Œå‡†ç¡®æ€§åˆ†æ]
"""
    
    def _get_comprehensive_report_template(self) -> str:
        """è·å–ç»¼åˆæŠ¥å‘Šæ¨¡æ¿"""
        return """# çŸ¥è¯†æ¶Œç°ç»¼åˆåˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {timestamp}

## æ‰§è¡Œæ‘˜è¦
[ç»¼åˆåˆ†ææ‘˜è¦]

## è¯¦ç»†åˆ†æ
[å®Œæ•´çš„åˆ†æç»“æœ]

## å»ºè®®ä¸ç»“è®º
[å…·ä½“çš„å»ºè®®å’Œç»“è®º]
"""