#!/usr/bin/env python3
"""
çŸ¥è¯†æ¶Œç°åˆ†æå·¥å…·æµ‹è¯•è„šæœ¬
éªŒè¯å„ä¸ªæ¨¡å—çš„åŸºæœ¬åŠŸèƒ½
"""

import sys
import os
import json
import tempfile
from pathlib import Path
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# å¯¼å…¥æ‰€æœ‰æ¨¡å—
try:
    from knowledge_emergence import (
        KnowledgeEmergenceAnalyzer,
        DataCollector,
        MetricsCalculator,
        QualityAssessor,
        PatternRecognizer,
        ValueAssessor,
        Visualizer,
        ReportGenerator
    )
    print("âœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)


def test_data_collector():
    """æµ‹è¯•æ•°æ®é‡‡é›†å™¨"""
    print("\næµ‹è¯•æ•°æ®é‡‡é›†å™¨...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = [
            {
                "title": "æµ‹è¯•çŸ¥è¯†1",
                "content": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•çŸ¥è¯†é¡¹çš„å†…å®¹ï¼Œç”¨äºéªŒè¯æ•°æ®é‡‡é›†åŠŸèƒ½ã€‚",
                "source": "æµ‹è¯•æ¥æº",
                "author": "æµ‹è¯•ä½œè€…"
            },
            {
                "title": "æµ‹è¯•çŸ¥è¯†2", 
                "content": "è¿™æ˜¯å¦ä¸€ä¸ªæµ‹è¯•çŸ¥è¯†é¡¹ï¼ŒåŒ…å«æ›´å¤šè¯¦ç»†ä¿¡æ¯ç”¨äºæµ‹è¯•ã€‚",
                "source": "æµ‹è¯•æ¥æº2",
                "author": "æµ‹è¯•ä½œè€…2"
            }
        ]
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False, encoding='utf-8') as f:
            json.dump(test_data, f, ensure_ascii=False, indent=2)
            temp_file = f.name
        
        try:
            # æµ‹è¯•æ•°æ®é‡‡é›†
            collector = DataCollector()
            collected_data = collector.collect_from_file(temp_file, 'json')
            
            if len(collected_data) == 2:
                print("  âœ“ æ•°æ®é‡‡é›†åŠŸèƒ½æ­£å¸¸")
                
                # æµ‹è¯•æ•°æ®é¢„å¤„ç†
                processed_data = collector.preprocess_data(collected_data)
                print(f"  âœ“ æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå¤„ç†äº† {len(processed_data)} æ¡æ•°æ®")
                
                return processed_data
            else:
                print(f"  âœ— æ•°æ®é‡‡é›†æ•°é‡ä¸æ­£ç¡®: æœŸæœ›2ï¼Œå®é™…{len(collected_data)}")
                return []
                
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file):
                os.unlink(temp_file)
                
    except Exception as e:
        print(f"  âœ— æ•°æ®é‡‡é›†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return []


def test_metrics_calculator(knowledge_items):
    """æµ‹è¯•æŒ‡æ ‡è®¡ç®—å™¨"""
    print("\næµ‹è¯•æŒ‡æ ‡è®¡ç®—å™¨...")
    
    if not knowledge_items:
        print("  âœ— æ— æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡æŒ‡æ ‡è®¡ç®—å™¨æµ‹è¯•")
        return {}
    
    try:
        calculator = MetricsCalculator()
        metrics = calculator.calculate_all_metrics(knowledge_items)
        
        if isinstance(metrics, dict) and 'overall' in metrics:
            print("  âœ“ æŒ‡æ ‡è®¡ç®—åŠŸèƒ½æ­£å¸¸")
            print(f"    - è®¡ç®—äº† {len([k for k, v in metrics.items() if isinstance(v, dict) and 'score' in v])} ä¸ªç»´åº¦")
            return metrics
        else:
            print("  âœ— æŒ‡æ ‡è®¡ç®—ç»“æœæ ¼å¼ä¸æ­£ç¡®")
            return {}
            
    except Exception as e:
        print(f"  âœ— æŒ‡æ ‡è®¡ç®—å™¨æµ‹è¯•å¤±è´¥: {e}")
        return {}


def test_quality_assessor(knowledge_items):
    """æµ‹è¯•è´¨é‡è¯„ä¼°å™¨"""
    print("\næµ‹è¯•è´¨é‡è¯„ä¼°å™¨...")
    
    if not knowledge_items:
        print("  âœ— æ— æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡è´¨é‡è¯„ä¼°å™¨æµ‹è¯•")
        return []
    
    try:
        assessor = QualityAssessor()
        quality_scores = assessor.assess_batch_quality(knowledge_items)
        
        if len(quality_scores) == len(knowledge_items):
            print("  âœ“ è´¨é‡è¯„ä¼°åŠŸèƒ½æ­£å¸¸")
            print(f"    - è¯„ä¼°äº† {len(quality_scores)} ä¸ªè´¨é‡åˆ†æ•°")
            
            # æ£€æŸ¥è´¨é‡åˆ†æ•°æ ¼å¼
            if hasattr(quality_scores[0], '__dict__'):
                print("  âœ“ è´¨é‡åˆ†æ•°æ ¼å¼æ­£ç¡®")
            
            return quality_scores
        else:
            print(f"  âœ— è´¨é‡è¯„ä¼°æ•°é‡ä¸æ­£ç¡®: æœŸæœ›{len(knowledge_items)}ï¼Œå®é™…{len(quality_scores)}")
            return []
            
    except Exception as e:
        print(f"  âœ— è´¨é‡è¯„ä¼°å™¨æµ‹è¯•å¤±è´¥: {e}")
        return []


def test_pattern_recognizer(knowledge_items):
    """æµ‹è¯•æ¨¡å¼è¯†åˆ«å™¨"""
    print("\næµ‹è¯•æ¨¡å¼è¯†åˆ«å™¨...")
    
    if not knowledge_items:
        print("  âœ— æ— æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡æ¨¡å¼è¯†åˆ«å™¨æµ‹è¯•")
        return []
    
    try:
        recognizer = PatternRecognizer()
        
        # æµ‹è¯•å„ç§æ¨¡å¼è¯†åˆ«
        temporal_patterns = recognizer.identify_temporal_patterns(knowledge_items)
        content_patterns = recognizer.identify_content_patterns(knowledge_items)
        structural_patterns = recognizer.identify_structural_patterns(knowledge_items)
        emergence_patterns = recognizer.identify_emergence_patterns(knowledge_items)
        
        all_patterns = temporal_patterns + content_patterns + structural_patterns + emergence_patterns
        
        print("  âœ“ æ¨¡å¼è¯†åˆ«åŠŸèƒ½æ­£å¸¸")
        print(f"    - è¯†åˆ«äº† {len(all_patterns)} ä¸ªæ¨¡å¼")
        print(f"      * æ—¶é—´æ¨¡å¼: {len(temporal_patterns)}")
        print(f"      * å†…å®¹æ¨¡å¼: {len(content_patterns)}")
        print(f"      * ç»“æ„æ¨¡å¼: {len(structural_patterns)}")
        print(f"      * æ¶Œç°æ¨¡å¼: {len(emergence_patterns)}")
        
        return all_patterns
        
    except Exception as e:
        print(f"  âœ— æ¨¡å¼è¯†åˆ«å™¨æµ‹è¯•å¤±è´¥: {e}")
        return []


def test_value_assessor(knowledge_items):
    """æµ‹è¯•ä»·å€¼è¯„ä¼°å™¨"""
    print("\næµ‹è¯•ä»·å€¼è¯„ä¼°å™¨...")
    
    if not knowledge_items:
        print("  âœ— æ— æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡ä»·å€¼è¯„ä¼°å™¨æµ‹è¯•")
        return []
    
    try:
        assessor = ValueAssessor()
        value_assessments = assessor.assess_batch_value(knowledge_items)
        
        if len(value_assessments) == len(knowledge_items):
            print("  âœ“ ä»·å€¼è¯„ä¼°åŠŸèƒ½æ­£å¸¸")
            print(f"    - è¯„ä¼°äº† {len(value_assessments)} ä¸ªä»·å€¼åˆ†æ•°")
            
            # æ£€æŸ¥ä»·å€¼è¯„ä¼°æ ¼å¼
            if hasattr(value_assessments[0], '__dict__'):
                print("  âœ“ ä»·å€¼è¯„ä¼°æ ¼å¼æ­£ç¡®")
            
            return value_assessments
        else:
            print(f"  âœ— ä»·å€¼è¯„ä¼°æ•°é‡ä¸æ­£ç¡®: æœŸæœ›{len(knowledge_items)}ï¼Œå®é™…{len(value_assessments)}")
            return []
            
    except Exception as e:
        print(f"  âœ— ä»·å€¼è¯„ä¼°å™¨æµ‹è¯•å¤±è´¥: {e}")
        return []


def test_visualizer(metrics, quality_scores, patterns, value_assessments):
    """æµ‹è¯•å¯è§†åŒ–ç”Ÿæˆå™¨"""
    print("\næµ‹è¯•å¯è§†åŒ–ç”Ÿæˆå™¨...")
    
    try:
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            visualizer = Visualizer({'output_dir': temp_dir})
            
            # æµ‹è¯•æŒ‡æ ‡å¯è§†åŒ–
            viz_file = visualizer.generate_metrics_visualization(metrics, "test_metrics.png")
            if viz_file and Path(viz_file).exists():
                print("  âœ“ æŒ‡æ ‡å¯è§†åŒ–ç”Ÿæˆæ­£å¸¸")
            else:
                print("  âœ— æŒ‡æ ‡å¯è§†åŒ–ç”Ÿæˆå¤±è´¥")
            
            # æµ‹è¯•æ¨¡å¼å¯è§†åŒ–
            viz_file = visualizer.generate_pattern_visualization(patterns, "test_patterns.png")
            if viz_file and Path(viz_file).exists():
                print("  âœ“ æ¨¡å¼å¯è§†åŒ–ç”Ÿæˆæ­£å¸¸")
            else:
                print("  âœ— æ¨¡å¼å¯è§†åŒ–ç”Ÿæˆå¤±è´¥")
            
            # æµ‹è¯•è´¨é‡å¯è§†åŒ–
            viz_file = visualizer.generate_quality_visualization(quality_scores, "test_quality.png")
            if viz_file and Path(viz_file).exists():
                print("  âœ“ è´¨é‡å¯è§†åŒ–ç”Ÿæˆæ­£å¸¸")
            else:
                print("  âœ— è´¨é‡å¯è§†åŒ–ç”Ÿæˆå¤±è´¥")
            
            # æµ‹è¯•ä»·å€¼å¯è§†åŒ–
            viz_file = visualizer.generate_value_visualization(value_assessments, "test_value.png")
            if viz_file and Path(viz_file).exists():
                print("  âœ“ ä»·å€¼å¯è§†åŒ–ç”Ÿæˆæ­£å¸¸")
            else:
                print("  âœ— ä»·å€¼å¯è§†åŒ–ç”Ÿæˆå¤±è´¥")
                
    except Exception as e:
        print(f"  âœ— å¯è§†åŒ–ç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")


def test_report_generator(knowledge_items, metrics, quality_scores, patterns, value_assessments):
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""
    print("\næµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨...")
    
    try:
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            generator = ReportGenerator({'output_dir': temp_dir})
            
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            analysis_data = {
                'knowledge_items': knowledge_items,
                'metrics': metrics,
                'quality_scores': quality_scores,
                'patterns': patterns,
                'value_assessments': value_assessments
            }
            
            # æµ‹è¯•æ‰§è¡Œæ‘˜è¦
            exec_file = generator.generate_executive_summary(analysis_data, "test_exec.md")
            if exec_file and Path(exec_file).exists():
                print("  âœ“ æ‰§è¡Œæ‘˜è¦ç”Ÿæˆæ­£å¸¸")
            else:
                print("  âœ— æ‰§è¡Œæ‘˜è¦ç”Ÿæˆå¤±è´¥")
            
            # æµ‹è¯•æŠ€æœ¯æŠ¥å‘Š
            tech_file = generator.generate_technical_report(analysis_data, "test_tech.md")
            if tech_file and Path(tech_file).exists():
                print("  âœ“ æŠ€æœ¯æŠ¥å‘Šç”Ÿæˆæ­£å¸¸")
            else:
                print("  âœ— æŠ€æœ¯æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
            
            # æµ‹è¯•ç»¼åˆæŠ¥å‘Š
            comp_file = generator.generate_comprehensive_report(analysis_data, "test_comp.md")
            if comp_file and Path(comp_file).exists():
                print("  âœ“ ç»¼åˆæŠ¥å‘Šç”Ÿæˆæ­£å¸¸")
            else:
                print("  âœ— ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥")
            
            # æµ‹è¯•JSONæŠ¥å‘Š
            json_file = generator.generate_json_report(analysis_data, "test_data.json")
            if json_file and Path(json_file).exists():
                print("  âœ“ JSONæŠ¥å‘Šç”Ÿæˆæ­£å¸¸")
            else:
                print("  âœ— JSONæŠ¥å‘Šç”Ÿæˆå¤±è´¥")
            
            # æµ‹è¯•HTMLæŠ¥å‘Š
            html_file = generator.generate_html_report(analysis_data, "test_report.html")
            if html_file and Path(html_file).exists():
                print("  âœ“ HTMLæŠ¥å‘Šç”Ÿæˆæ­£å¸¸")
            else:
                print("  âœ— HTMLæŠ¥å‘Šç”Ÿæˆå¤±è´¥")
                
    except Exception as e:
        print(f"  âœ— æŠ¥å‘Šç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")


def test_main_analyzer():
    """æµ‹è¯•ä¸»åˆ†æå™¨"""
    print("\næµ‹è¯•ä¸»åˆ†æå™¨...")
    
    try:
        # åˆ›å»ºä¸´æ—¶æµ‹è¯•æ•°æ®
        test_data = [
            {
                "title": "ä¸»åˆ†æå™¨æµ‹è¯•çŸ¥è¯†",
                "content": "è¿™æ˜¯ç”¨äºæµ‹è¯•ä¸»åˆ†æå™¨åŠŸèƒ½çš„çŸ¥è¯†é¡¹ã€‚",
                "source": "æµ‹è¯•æ¥æº",
                "author": "æµ‹è¯•ä½œè€…",
                "_collection_time": datetime.now().isoformat()
            }
        ]
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False, encoding='utf-8') as f:
            json.dump(test_data, f, ensure_ascii=False, indent=2)
            temp_file = f.name
        
        try:
            # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
            with tempfile.TemporaryDirectory() as temp_output:
                analyzer = KnowledgeEmergenceAnalyzer()
                
                # æµ‹è¯•å¿«é€Ÿåˆ†æ
                quick_result = analyzer.quick_analysis(temp_file, temp_output)
                if quick_result['status'] == 'success':
                    print("  âœ“ å¿«é€Ÿåˆ†æåŠŸèƒ½æ­£å¸¸")
                else:
                    print(f"  âœ— å¿«é€Ÿåˆ†æå¤±è´¥: {quick_result.get('error', 'Unknown error')}")
                
                # æµ‹è¯•å®Œæ•´åˆ†æ
                full_result = analyzer.analyze(temp_file, temp_output)
                if full_result['status'] == 'success':
                    print("  âœ“ å®Œæ•´åˆ†æåŠŸèƒ½æ­£å¸¸")
                    print(f"    - åˆ†æäº† {full_result['knowledge_items_count']} ä¸ªçŸ¥è¯†é¡¹")
                else:
                    print(f"  âœ— å®Œæ•´åˆ†æå¤±è´¥: {full_result.get('error', 'Unknown error')}")
                    
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file):
                os.unlink(temp_file)
                
    except Exception as e:
        print(f"  âœ— ä¸»åˆ†æå™¨æµ‹è¯•å¤±è´¥: {e}")


def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\næµ‹è¯•é”™è¯¯å¤„ç†...")
    
    try:
        # æµ‹è¯•æ— æ•ˆæ•°æ®
        analyzer = KnowledgeEmergenceAnalyzer()
        
        # æµ‹è¯•ä¸å­˜åœ¨çš„æ–‡ä»¶
        result = analyzer.quick_analysis("nonexistent_file.json", "temp_output")
        if result['status'] == 'error':
            print("  âœ“ æ— æ•ˆæ–‡ä»¶é”™è¯¯å¤„ç†æ­£å¸¸")
        else:
            print("  âœ— æ— æ•ˆæ–‡ä»¶é”™è¯¯å¤„ç†å¼‚å¸¸")
        
        # æµ‹è¯•ç©ºæ•°æ®
        empty_data = []
        collector = DataCollector()
        processed = collector.preprocess_data(empty_data)
        if len(processed) == 0:
            print("  âœ“ ç©ºæ•°æ®å¤„ç†æ­£å¸¸")
        else:
            print("  âœ— ç©ºæ•°æ®å¤„ç†å¼‚å¸¸")
            
    except Exception as e:
        print(f"  âœ— é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("çŸ¥è¯†æ¶Œç°åˆ†æå·¥å…·æµ‹è¯•")
    print("=" * 40)
    
    # è®°å½•æµ‹è¯•ç»“æœ
    test_results = []
    
    try:
        # æµ‹è¯•å„ä¸ªæ¨¡å—
        knowledge_items = test_data_collector()
        test_results.append(("æ•°æ®é‡‡é›†å™¨", len(knowledge_items) > 0))
        
        metrics = test_metrics_calculator(knowledge_items)
        test_results.append(("æŒ‡æ ‡è®¡ç®—å™¨", bool(metrics)))
        
        quality_scores = test_quality_assessor(knowledge_items)
        test_results.append(("è´¨é‡è¯„ä¼°å™¨", len(quality_scores) > 0))
        
        patterns = test_pattern_recognizer(knowledge_items)
        test_results.append(("æ¨¡å¼è¯†åˆ«å™¨", len(patterns) >= 0))  # æ¨¡å¼å¯èƒ½ä¸ºç©º
        
        value_assessments = test_value_assessor(knowledge_items)
        test_results.append(("ä»·å€¼è¯„ä¼°å™¨", len(value_assessments) > 0))
        
        test_visualizer(metrics, quality_scores, patterns, value_assessments)
        test_results.append(("å¯è§†åŒ–ç”Ÿæˆå™¨", True))  # å¯è§†åŒ–æµ‹è¯•ä¸è¿”å›å¸ƒå°”å€¼
        
        test_report_generator(knowledge_items, metrics, quality_scores, patterns, value_assessments)
        test_results.append(("æŠ¥å‘Šç”Ÿæˆå™¨", True))  # æŠ¥å‘Šæµ‹è¯•ä¸è¿”å›å¸ƒå°”å€¼
        
        test_main_analyzer()
        test_results.append(("ä¸»åˆ†æå™¨", True))  # ä¸»åˆ†æå™¨æµ‹è¯•ä¸è¿”å›å¸ƒå°”å€¼
        
        test_error_handling()
        test_results.append(("é”™è¯¯å¤„ç†", True))  # é”™è¯¯å¤„ç†æµ‹è¯•ä¸è¿”å›å¸ƒå°”å€¼
        
    except Exception as e:
        print(f"\næµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    # æ±‡æ€»æµ‹è¯•ç»“æœ
    print("\n" + "=" * 40)
    print("æµ‹è¯•ç»“æœæ±‡æ€»:")
    print("=" * 40)
    
    passed = 0
    total = len(test_results)
    
    for module_name, result in test_results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{module_name:12} {status}")
        if result:
            passed += 1
    
    print("=" * 40)
    print(f"æ€»è®¡: {passed}/{total} ä¸ªæ¨¡å—æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å·¥å…·åŠŸèƒ½æ­£å¸¸ã€‚")
        return 0
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæ¨¡å—æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)